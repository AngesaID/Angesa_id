{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spell Check Indonesia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Pre-Trained Fasttext Model Indonesia\n",
    "Pre-trained Fasttext model yang diunduh adalah hasil pelatihan menggunakan metode CBOW dengan *position-weight*, dalam dimensi 300, dengan panjang karakter n-gram sebesar 5, *window size* 5 dan *negatives* 10. Link kumpulan pre-trained model Fasttext dapat diunduh [disini](https://fasttext.cc/docs/en/crawl-vectors.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "def bar_progress(current, total, width=80):\n",
    "    progress_message = \"Downloading: %d%% [%d / %d] bytes\" % (current / total * 100, current, total)\n",
    "     # Don't use print() as it will print in new line every time.\n",
    "    sys.stdout.write(\"\\r\" + progress_message)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.bin.gz'\n",
    "\n",
    "filename = wget.download(url, bar=bar_progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract model dengan menggunakan `gunzip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "with gzip.open('cc.id.300.bin.gz', 'rb') as f_in:\n",
    "    with open('cc.id.300.bin', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import fasttext\n",
    "from gensim.models.fasttext import load_facebook_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Fasttext Model using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models._fasttext_bin:loading 2000000 words for fastText model from cc.id.300.bin\n",
      "INFO:gensim.utils:FastText lifecycle event {'params': 'FastText(vocab=0, vector_size=300, alpha=0.025)', 'datetime': '2021-12-29T15:29:48.397274', 'gensim': '4.1.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'created'}\n",
      "INFO:gensim.models.word2vec:Updating model with new vocabulary\n",
      "INFO:gensim.utils:FastText lifecycle event {'msg': 'added 2000000 new unique words (100.0%% of original 2000000) and increased the count of 0 pre-existing words (0.0%% of original 2000000)', 'datetime': '2021-12-29T15:29:59.371480', 'gensim': '4.1.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 2000000 items\n",
      "INFO:gensim.models.word2vec:sample=1e-05 downsamples 3652 most-common words\n",
      "INFO:gensim.utils:FastText lifecycle event {'msg': 'downsampling leaves estimated 2101363489.8742118 word corpus (39.4%% of prior 5336834474)', 'datetime': '2021-12-29T15:30:11.757850', 'gensim': '4.1.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.utils:FastText lifecycle event {'msg': 'loaded (4000000, 300) weight matrix for fastText model from cc.id.300.bin', 'datetime': '2021-12-29T15:31:37.880029', 'gensim': '4.1.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'load_fasttext_format'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = fasttext.load_facebook_model('cc.id.300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pada pre-trained model Fasttext terdapat 2.000.000 (dua juta) *vocabulary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = model.wv.key_to_index\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '.', '</s>', 'yang', 'dan', '\"', 'di', ')', '(', 'dengan']"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.wv.key_to_index)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index for each word in Vocabulary\n",
    "Buat *dictionary word-rank* pada tiap kata/karakter yang terdapat pada *vocabulary*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "words = list(model.wv.key_to_index)\n",
    "\n",
    "w_rank = {}\n",
    "for i,word in enumerate(words):\n",
    "    w_rank[word] = i\n",
    "    \n",
    "WORDS = w_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',': 0,\n",
       " '.': 1,\n",
       " '</s>': 2,\n",
       " 'yang': 3,\n",
       " 'dan': 4,\n",
       " '\"': 5,\n",
       " 'di': 6,\n",
       " ')': 7,\n",
       " '(': 8,\n",
       " 'dengan': 9}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "dict(itertools.islice(WORDS.items(), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peter Norvig Spelling Corrector\n",
    "Salah satu metode paling sederhana untuk Spelling Corrector adalah dengan metode yang diterapkan oleh [Peter Norvig.](https://norvig.com/spell-correct.html)\n",
    "\n",
    "### Perbedaan\n",
    "Terdapat perbedaaan pada code Peter Norvig dengan code CPMP untuk penerapan Spell Check. Perbedaannya jika menggunakan **code Peter Norvig dengan menghitung frekuensi dari tiap kata dari kamus**, sedangkan **code CPMP dengan menggunakan ranking dari Word2Vec model**.\n",
    "\n",
    "### Cara Kerja\n",
    "Spell Check ini menggunakan Teorema Bayes untuk menemukan *correction c* dengan memilih *probability* terbesar dari semua *probability candidate correction*. Metode tersebut dapat dijabarkan menjadi 4 bagian:\n",
    "1. **Selection Mechanism**: `argmax`, dengan memilih *candidate* yang memiliki *probability* terbesar.\n",
    "2. **Candidate Model:** `c âˆˆ candidates`, didapatkan *candidate corrections c*, untuk dipertimbangkan.\n",
    "3. **Languange Model**: `P(c)`, *probability* dari kemunculan *candidate corretion c* pada kamus. Pada penerapannya menggunakan kamus Word2Vec model.\n",
    "4. **Error Model**: `P(w|c)`, *probability* apabila yang diketik adalah kata *w* sedangkan yang dimaksud adalah *c*. Sebagai contoh, *probability* `P(mkan|makan)` lebih tinggi dibandingkan dengan *probability* `P(mkanxxxyz|makan)` yang lebih rendah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "def P(word): \n",
    "    \"Probability of `word`.\"\n",
    "    # use inverse of rank as proxy\n",
    "    # returns 0 if the word isn't in the dictionary\n",
    "    return - WORDS.get(word, 0)\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kucing'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction(\"kcing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jakarta'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('J4karta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'menyedihkan'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('mnyedihknn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yg'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('yg ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"source/slang.txt\") as f:\n",
    "    slangS = json.loads(f.read())\n",
    "    \n",
    "type(slangS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jangan ragu juragan, langsung saja di order pajangannya.'"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def slang(T):\n",
    "    Texts = re.findall(r\"[\\w']+|[.,!?;]\",T)\n",
    "    \n",
    "    _spelling = []\n",
    "    for text in Texts:\n",
    "        _spelling.append(correction(text))\n",
    "    \n",
    "    for index,text in enumerate(_spelling):\n",
    "        if text in slangS.keys():\n",
    "            _spelling[index] = slangS[text]\n",
    "            \n",
    "    _text = list(join_punctuation(_spelling))\n",
    "    _text = ' '.join(join_punctuation(_spelling))\n",
    "    return _text\n",
    "    \n",
    "slang('jangan ragu gan, langsung saja di order pajangannya.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Code Rev-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userinput(x):\n",
    "    \n",
    "    spellchecker = correction(x)\n",
    "    \n",
    "    removedslang = slang(spellchecker)\n",
    "    \n",
    "    Text = list(join_punctuation(removedslang))\n",
    "    Text = ' '.join(join_punctuation(Text))\n",
    "    \n",
    "    return Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jakarta'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userinput(\"J4karta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sinonim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('source/dict.json') as f:\n",
    "    mydict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSinonim(word):\n",
    "    if word in mydict.keys():\n",
    "        return mydict[word]['sinonim']\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "def getAntonim(word):\n",
    "    if word in mydict.keys():\n",
    "        if 'antonim' in mydict[word].keys():\n",
    "            return mydict[word]['antonim']\n",
    "    \n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aman', 'bahagia', 'bangga', 'berbungabunga ', 'berkenan', 'bungah', 'camar', 'ceria', 'doyan', 'enak', 'gemar', 'gembira', 'girang', 'lapang dada', 'lega', 'makmur', 'meriah', 'nikmat', 'nyaman', 'puas', 'ria', 'riang', 'sejahtera', 'semarak', 'selesa', 'suka', 'sukacita', 'sukaria', 'tenang', 'tenteram']\n"
     ]
    }
   ],
   "source": [
    "print(getSinonim('senang'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['duka', 'getir ', 'gundah', 'lara', 'masygul', 'menyesak', 'merana', 'pedih', 'pilu', 'prihatin', 'sedu', 'susah hati', 'terharu', 'trenyuh']\n"
     ]
    }
   ],
   "source": [
    "print(getSinonim(getAntonim('senang')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "- https://github.com/louisowen6/NLP_bahasa_resources#pos-tagging\n",
    "- https://medium.com/@yasirabd/spell-check-indonesia-menggunakan-pre-trained-fasttext-model-14e90a3f1ac0\n",
    "- https://norvig.com/spell-correct.html"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4465b56ab07b4b37dd2120fd6e12a5c69113d1fe3c5a02503d475be473c9d9e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('myenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
